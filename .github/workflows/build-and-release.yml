name: Build llama.cpp with ROCm HIP (gfx1151)

on:
  push:
    tags:
      - "b*"
  workflow_dispatch:

permissions:
  contents: write

jobs:
  build:
    name: Build with HIP support
    runs-on: blacksmith-2vcpu-ubuntu-2404

    steps:
      # 1 Checkout this repo
      - name: Checkout source
        uses: actions/checkout@v6
    
      - name: Set version variables
        run: |
          echo "Setting LLAMA_CPP_VER variable"
          source ./llama_cpp_version
          echo "LLAMA_CPP_VER=$LLAMA_CPP_VER" >> $GITHUB_ENV
          echo "ROCM_VER=$ROCM_VER" >> $GITHUB_ENV

      # 2 Install CMake + build tools
      - name: Install build tools
        run: |
          sudo add-apt-repository universe
          sudo apt update
          sudo apt-get install -y \
            cmake \
            build-essential \
            ninja-build \
            ccache \
            libcurl4-openssl-dev \
            gcc-14 g++-14

      # 3 Install ROCm dev packages for compile-time HIP support
      - name: Install ROCm / HIP development packages
        run: |
          # Make the directory if it doesn't exist yet.
          # This location is recommended by the distribution maintainers.
          sudo mkdir --parents --mode=0755 /etc/apt/keyrings

          # Download the key, convert the signing-key to a full
          # keyring required by apt and store in the keyring directory
          wget https://repo.radeon.com/rocm/rocm.gpg.key -O - | \
            gpg --dearmor | sudo tee /etc/apt/keyrings/rocm.gpg > /dev/null
          
          sudo tee /etc/apt/sources.list.d/rocm.list << EOF
          deb [arch=amd64 signed-by=/etc/apt/keyrings/rocm.gpg] https://repo.radeon.com/rocm/apt/${ROCM_VER} noble main
          deb [arch=amd64 signed-by=/etc/apt/keyrings/rocm.gpg] https://repo.radeon.com/graphics/${ROCM_VER}/ubuntu noble main
          EOF

          sudo tee /etc/apt/preferences.d/rocm-pin-600 << EOF
          Package: *
          Pin: release o=repo.radeon.com
          Pin-Priority: 600
          EOF
          
          sudo apt-get update
          
          sudo apt-get install -y \
            rocm-hip-sdk \
            rocm \
            rocm-core \
            rocm-cmake \
            rocminfo

          # Check that hipcc exists
          hipcc --version

      # 4 Clone the official llama.cpp repo
      - name: Clone llama.cpp
        run: |
          git clone --depth 1 --branch $LLAMA_CPP_VER https://github.com/ggml-org/llama.cpp.git

      # 5 Configure & build with HIP and gfx1151
      - name: Configure and Build llama.cpp
        run: |
          cd llama.cpp
          sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-14 100
          sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-14 100
          gcc --version
          g++ --version
          export CFLAGS="-O3 -march=znver5 -mtune=znver5 -flto=auto"
          export CXXFLAGS="$CFLAGS"
          cmake -B build \
            -DCMAKE_BUILD_TYPE=Release \
            -DGGML_HIP=ON \
            -DGGML_CPU_TARGET="znver5" \
            -DAMDGPU_TARGETS="gfx1151"
          cmake --build build -- -j$(nproc)

      # 6 Package compiled binaries
      - name: Package artifacts
        run: |
          tar -cJf llama-cpp-${LLAMA_CPP_VER}-rocm-${ROCM_VER}-gfx1151.tar.xz -C llama.cpp/build/bin .

      # 7 Upload the built artifacts
      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: llama-cpp-strix-halo
          path: llama-cpp-*.tar.xz
          retention-days: 1

  release:
    needs: build
    runs-on: ubuntu-latest
    if: github.ref_type == 'tag'
    
    steps:
      - name: Checkout source
        uses: actions/checkout@v6
 
      - name: Set version variables
        run: |
          echo "Setting LLAMA_CPP_VER variable"
          source ./llama_cpp_version
          echo "LLAMA_CPP_VER=$LLAMA_CPP_VER" >> $GITHUB_ENV
          echo "ROCM_VER=$ROCM_VER" >> $GITHUB_ENV

      - name: Download llama-cpp-strix-halo artifact
        uses: actions/download-artifact@v4
        with:
          name: llama-cpp-strix-halo 
          path: ./release
      
      - name: List files
        run: |
          echo "Files to be released:"
          ls -lh ./release/
      
      - name: Create GitHub Release
        uses: softprops/action-gh-release@v2
        with:
          files: ./release/*
          body: |
            `llama.cpp` (${{ env.LLAMA_CPP_VER }}) compiled for Linux x86_64 with ROCm (${{ env.ROCM_VER }}), optimized for AMD Strix Halo devices.
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
