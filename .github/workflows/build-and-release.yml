name: Build llama.cpp with ROCm HIP (gfx1151)

on:
  push:
    tags:
      - "v*"
  workflow_dispatch:

jobs:
  build:
    name: Build with HIP support
    runs-on: ubuntu-latest

    steps:
      # 1 Checkout this repo
      - name: Checkout source
        uses: actions/checkout@v6
    
      - name: Set LLAMA_CPP_VER variable
        run: |
          echo "Setting LLAMA_CPP_VER variable"
          source ./llama_cpp_version
          echo "LLAMA_CPP_VER=$LLAMA_CPP_VER" >> $GITHUB_ENV

      # 2 Install ROCm dev packages for compile-time HIP support
      - name: Install ROCm / HIP development packages
        run: |
          wget -qO - https://repo.radeon.com/rocm/rocm.gpg.key | sudo tee /etc/apt/trusted.gpg.d/rocm.gpg >/dev/null
          
          sudo tee /etc/apt/sources.list.d/rocm.list << EOF
          deb [arch=amd64 signed-by=/etc/apt/trusted.gpg.d/rocm.gpg] https://repo.radeon.com/rocm/apt/7.1.1 noble main
          deb [arch=amd64 signed-by=/etc/apt/trusted.gpg.d/rocm.gpg] https://repo.radeon.com/graphics/7.1.1/ubuntu noble main
          EOF

          sudo tee /etc/apt/preferences.d/rocm-pin-600 << EOF
          Package: *
          Pin: release o=repo.radeon.com
          Pin-Priority: 600
          EOF
          
          sudo apt-get update
          
          sudo apt-get install -y \
            rocm-hip-sdk \
            rocm-hip-runtime-dev \
            rocm-core \
            rocm-cmake \
            rocminfo

          # Check that hipcc exists
          hipcc --version

      # 3 Install CMake + build tools
      - name: Install build tools
        run: |
          sudo apt-get install -y cmake build-essential ninja-build

      # 4 Clone the official llama.cpp repo
      - name: Clone llama.cpp
        run: |
          git clone --depth 1 --branch $LLAMA_CPP_VER https://github.com/ggml-org/llama.cpp.git

      # 5 Configure & build with HIP and gfx1151
      - name: Configure and Build llama.cpp
        run: |
          cd llama.cpp
          cmake -B build \
            -DCMAKE_BUILD_TYPE=Release \
            -DGGML_HIP=ON \
            -DAMDGPU_TARGETS="gfx1151"
          cmake --build build -- -j$(nproc)

      # 6 Package compiled binaries
      - name: Package artifacts
        run: |
          tar -cJf llama-cpp-hip-gfx1151.tar.xz -C llama.cpp/build/bin .

      # 7 Upload the built artifacts
      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: llama-cpp-strix-halo 
          path: llama-cpp-hip-gfx1151.tar.xz
          retention-days: 1